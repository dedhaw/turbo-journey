from fastapi import WebSocket, WebSocketDisconnect
import logging
import asyncio
from deepgram import DeepgramClient, LiveOptions, SpeakOptions
from dotenv import load_dotenv
import os
import json
import queue
import tempfile
import base64

from ..agent.response import ai_response

from .helper import split_into_sentences, handle_command, create_deepgram_connection

load_dotenv()

DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')
deepgram = DeepgramClient(DEEPGRAM_API_KEY)

async def live_audio_transcription(sentence):
    try:
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
            temp_filename = temp_file.name
            
        speak_options = {"text": sentence}
        options = SpeakOptions(
            model="aura-2-thalia-en",
        )
        
        _ = deepgram.speak.rest.v("1").save(temp_filename, speak_options, options)
        
        with open(temp_filename, 'rb') as f:
            audio_bytes = f.read()
            
        # Clean up the temporary file
        try:
            os.unlink(temp_filename)
        except:
            pass
            
        return audio_bytes
    
    except Exception as e:
        logging.error(f"Error generating speech for sentence: {e}")
        return None

async def live_text_transcription(websocket: WebSocket):
    """This method uses deepgram api to convert audio into text, which is
    sent to the client side via a websocket. In this current version I am
    returning text, but in the next version I will be returning audio
    generated by deepgram.

    Args:
        websocket (WebSocket): This is the current open websocket, which 
        must have a connection estabilished before using deepgram to convert
        the audio to text.
    """
    
    transcript_queue = queue.Queue()
    
    async def process_transcript():
        """Process and send the output from the current transcript queue to 
        the frontend via websockets.
        """
        while True:
            if not transcript_queue.empty():
                transcript = transcript_queue.get()
                
                print(f"User Input: {transcript}")
                response_text = ai_response(transcript)
                print(f"AI Response: {response_text}")
                
                sentences = await split_into_sentences(response_text)
                
                await websocket.send_text(json.dumps({"transcript": response_text}))
                
                for sentence in sentences:
                    audio_bytes = await live_audio_transcription(sentence)
                    
                    if audio_bytes:
                        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                        await websocket.send_text(json.dumps({
                            "audio": audio_base64,
                            "content_type": "audio/mp3",
                            "sentence": sentence
                        }))
                        
                        await asyncio.sleep(0.1)
                
            await asyncio.sleep(0.1)
    
    queue_task = asyncio.create_task(process_transcript())
    conn = None
    
    def on_message(sender, result, **kwargs):
        try:
            transcript = result.channel.alternatives[0].transcript
            if len(transcript) > 0:
                logging.info(f"Transcript: {transcript}")
                transcript_queue.put(transcript)
        except Exception as e:
            logging.error(f"Error processing transcript: {e}")
    
    options = LiveOptions(
        model="nova-3", 
        interim_results=False, 
        language="en-US",
        punctuate=True,
        diarize=True,
        endpointing=7000
    )
    
    try:
        await websocket.send_text(json.dumps({
            "status": "ready",
            "message": "Server ready to accept commands"
        }))
        
        while True:
            try:
                message_data = await websocket.receive()
                
                if "text" in message_data:
                    try:
                        message = json.loads(message_data["text"])
                        conn = await handle_command(websocket, conn, message, on_message, deepgram, options)
                        
                        if message.get("type") == "audio" and message.get("data"):
                            if conn and conn.is_connected():
                                audio_data = base64.b64decode(message["data"])
                                conn.send(audio_data)
                    
                    except json.JSONDecodeError:
                        logging.error("Received invalid JSON message")
                
                elif "bytes" in message_data:
                    if conn and conn.is_connected():
                        conn.send(message_data["bytes"])
                    else:
                        if not conn:
                            conn, _ = await create_deepgram_connection(on_message, deepgram, options)
                            await websocket.send_text(json.dumps({
                                "status": "listening",
                                "message": "Auto-started listening"
                            }))
                        
                        if conn:
                            conn.send(message_data["bytes"])
                
            except WebSocketDisconnect:
                logging.info("WebSocket disconnected")
                break
            
            except Exception as e:
                logging.error(f"Error processing data: {e}")
                await websocket.send_text(json.dumps({"error": str(e)}))
                
    except WebSocketDisconnect:
        logging.info("Disconnected")
    except Exception as e:
        logging.error(f"Error in WebSocket handler: {e}")
    
    finally:
        try:
            if conn in locals():
                conn.finish()
            if queue_task in locals():
                queue_task.cancel()
        except Exception as e:
            logging.error(f"Error in cleaning connection or finalizing events: {e}")