from fastapi import WebSocket, WebSocketDisconnect
import logging
import asyncio
from deepgram import DeepgramClient, LiveOptions, SpeakOptions
from dotenv import load_dotenv
import os
import json
import queue
import tempfile
import base64
import time

from ..agent.response import ai_response

from .helper import split_into_sentences, handle_command, create_deepgram_connection

load_dotenv()

DEEPGRAM_API_KEY = os.getenv('DEEPGRAM_API_KEY')
deepgram = DeepgramClient(DEEPGRAM_API_KEY)

async def live_audio_transcription(sentence):
    try:
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
            temp_filename = temp_file.name
            
        speak_options = {"text": sentence}
        options = SpeakOptions(
            model="aura-2-thalia-en",
        )
        
        _ = deepgram.speak.rest.v("1").save(temp_filename, speak_options, options)
        
        with open(temp_filename, 'rb') as f:
            audio_bytes = f.read()
            
        try:
            os.unlink(temp_filename)
        except:
            pass
            
        return audio_bytes
    
    except Exception as e:
        logging.error(f"Error generating speech for sentence: {e}")
        return None

async def live_text_transcription(websocket: WebSocket):
    """This method uses deepgram api to convert audio into text, which is
    sent to the client side via a websocket. In this current version I am
    returning text, but in the next version I will be returning audio
    generated by deepgram.

    Args:
        websocket (WebSocket): This is the current open websocket, which 
        must have a connection estabilished before using deepgram to convert
        the audio to text.
    """
    
    transcript_queue = queue.Queue()
    ai_speaking_start_time = None
    ai_currently_speaking = False
    last_audio_time = time.time()
    
    async def send_keepalive(conn):
        """Send periodic keepalive to prevent Deepgram timeout during AI speech"""
        while True:
            await asyncio.sleep(8)
            current_time = time.time()
            
            if (ai_currently_speaking and 
                current_time - last_audio_time > 8 and 
                conn and hasattr(conn, 'is_connected') and conn.is_connected()):
                try:
                    silent_audio = b'\x00' * 320
                    conn.send(silent_audio)
                    print("Sent keepalive to Deepgram during AI speech")
                except Exception as e:
                    print(f"Keepalive failed: {e}")
                    break
    
    async def process_transcript():
        """Process and send the output from the current transcript queue to 
        the frontend via websockets.
        """
        nonlocal ai_speaking_start_time, ai_currently_speaking
        
        while True:
            if not transcript_queue.empty():
                transcript_data = transcript_queue.get()
                transcript = transcript_data["transcript"]
                transcript_time = transcript_data["timestamp"]
                
                # Check if AI is currently speaking and if user input should be ignored or treated as interruption
                if ai_currently_speaking and ai_speaking_start_time:
                    time_since_ai_started = transcript_time - ai_speaking_start_time
                    
                    # Interuption after 2 senconds
                    if time_since_ai_started <= 2.0:
                        print(f"Ignoring user input during AI speech (within 2 seconds): {transcript}")
                        continue
                    else:
                        print(f"User interruption detected: {transcript}")
                        ai_currently_speaking = False
                        ai_speaking_start_time = None
                        await websocket.send_text(json.dumps({"interrupt": True}))
                
                if not ai_currently_speaking:
                    if hasattr(process_transcript, 'partial_transcript'):
                        transcript = process_transcript.partial_transcript + " " + transcript
                        delattr(process_transcript, 'partial_transcript')
                    
                    sentence_endings = ['.', '!', '?', 'â€¦']
                    has_ending = any(transcript.rstrip().endswith(ending) for ending in sentence_endings)
                    
                    if not has_ending and not transcript.endswith('...'):
                        process_transcript.partial_transcript = transcript
                        print(f"Incomplete sentence, keeping in buffer: {transcript}")
                        continue
                    
                    # Complete sentence found
                    print(f"User Input: {transcript}")
                    
                    ai_currently_speaking = True
                    ai_speaking_start_time = time.time()
                    
                    response_text = ai_response(transcript)
                    print(f"AI Response: {response_text}")
                    
                    sentences = await split_into_sentences(response_text)
                    
                    await websocket.send_text(json.dumps({"transcript": response_text}))
                    
                    for i, sentence in enumerate(sentences):
                        if not ai_currently_speaking:
                            print(f"AI speech interrupted, stopping at sentence {i}")
                            break
                            
                        print(f"Generating audio for sentence {i+1}/{len(sentences)}: {sentence}")
                        audio_bytes = await live_audio_transcription(sentence)
                        
                        if not ai_currently_speaking:
                            print(f"AI speech interrupted during audio generation for sentence {i}")
                            break
                        
                        if audio_bytes:
                            audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
                            await websocket.send_text(json.dumps({
                                "audio": audio_base64,
                                "content_type": "audio/mp3",
                                "sentence": sentence
                            }))
                            
                            await asyncio.sleep(0.1)
                    
                    if ai_currently_speaking:
                        print("AI finished speaking")
                        ai_currently_speaking = False
                        ai_speaking_start_time = None
                        
                        await websocket.send_text(json.dumps({"ai_finished_speaking": True}))
                
            await asyncio.sleep(0.1)
    
    queue_task = asyncio.create_task(process_transcript())
    conn = None
    keepalive_task = None
    
    def on_message(sender, result, **kwargs):
        try:
            transcript = result.channel.alternatives[0].transcript
            is_final = getattr(result, 'is_final', None)
            if is_final is None:
                is_final = getattr(result.channel.alternatives[0], 'is_final', False)
            
            if is_final and len(transcript) > 0:
                print(f"Final transcript: {transcript}")
                transcript_queue.put({
                    "transcript": transcript,
                    "timestamp": time.time()
                })
            else:
                print("Interim transcript ignored")
        except Exception as e:
            logging.error(f"Error processing transcript: {e}")
    
    options: LiveOptions = LiveOptions(
        model="nova-3", 
        interim_results=True, 
        language="en-US",
        punctuate=True,
        diarize=True,
        endpointing=300,
        vad_events=True,
        smart_format=True,
        utterance_end_ms="1000"
    )
    
    try:
        await websocket.send_text(json.dumps({
            "status": "ready",
            "message": "Server ready to accept commands"
        }))
        
        while True:
            try:
                message_data = await websocket.receive()
                
                if "text" in message_data:
                    try:
                        message = json.loads(message_data["text"])
                        conn = await handle_command(websocket, conn, message, on_message, deepgram, options)
                        
                        if conn and not keepalive_task:
                            keepalive_task = asyncio.create_task(send_keepalive(conn))
                        
                        if message.get("action") == "stop_listening":
                            print("Stop listening command received")
                            
                            if ai_currently_speaking:
                                print("Stopping AI speech due to stop command")
                                ai_currently_speaking = False
                                ai_speaking_start_time = None
                            
                            if keepalive_task:
                                keepalive_task.cancel()
                                keepalive_task = None
                                print("Cancelled keepalive task")
                            
                            if conn:
                                try:
                                    print("Closing Deepgram connection - stop recording requested")
                                    conn.finish()
                                    conn = None
                                    print("Deepgram connection closed successfully")
                                except Exception as e:
                                    print(f"Error closing Deepgram connection: {e}")
                            
                            await websocket.send_text(json.dumps({
                                "status": "stopped",
                                "message": "Connection closed"
                            }))
                            
                            print("Stop listening completed")
                        
                        if message.get("type") == "audio" and message.get("data"):
                            if conn and conn.is_connected() and not ai_currently_speaking:
                                audio_data = base64.b64decode(message["data"])
                                conn.send(audio_data)
                                last_audio_time = time.time()
                    
                    except json.JSONDecodeError:
                        logging.error("Received invalid JSON message")
                
                elif "bytes" in message_data:
                    # Only send audio if AI is not currently speaking
                    if not ai_currently_speaking:
                        last_audio_time = time.time()
                        
                        if conn and conn.is_connected():
                            conn.send(message_data["bytes"])
                        else:
                            if not conn:
                                conn, _ = await create_deepgram_connection(on_message, deepgram, options)
                                # Start keepalive task when connection is created
                                if conn and not keepalive_task:
                                    keepalive_task = asyncio.create_task(send_keepalive(conn))
                                await websocket.send_text(json.dumps({
                                    "status": "listening",
                                    "message": "Auto-started listening"
                                }))
                            
                            if conn:
                                conn.send(message_data["bytes"])
                    else:
                        print("AI is speaking, ignoring audio bytes")
                
            except WebSocketDisconnect:
                logging.info("WebSocket disconnected")
                break
            
            except Exception as e:
                logging.error(f"Error processing data: {e}")
                await websocket.send_text(json.dumps({"error": str(e)}))
                
    except WebSocketDisconnect:
        logging.info("Disconnected")
    except Exception as e:
        logging.error(f"Error in WebSocket handler: {e}")
    
    finally:
        try:
            if keepalive_task:
                keepalive_task.cancel()
            if conn in locals() or conn:
                try:
                    logging.info("Closing Deepgram connection in finally block")
                    conn.finish()
                except Exception as e:
                    logging.error(f"Error closing Deepgram connection in finally: {e}")
            if queue_task in locals():
                queue_task.cancel()
        except Exception as e:
            logging.error(f"Error in cleaning connection or finalizing events: {e}")